{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkConf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col, size\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "from bio_spark.io.fasta_reader import FASTAReader, FASTAQReader\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre este Notebook\n",
    "\n",
    "Este notebook executa uma clusterização de seuência de Aminoácidos usando a ML lib dp Spark. Clustrização é um método que pode auxiliar os pesquisadores a descobrir relações filogenéticas e/ou relações de similaridade entre sequências sem a necessidade de comparar com uma base de referência. O fluxo é composto dos seguintes passos:\n",
    "\n",
    "1. Leutra e parsing do arquivos fasta de entrada\n",
    "2. Cálculo dos Kmers a partir das sequências encontradas nos arquivos de entrada\n",
    "3. Uso do método de Elbow para encontrar clusters coesos.\n",
    "\n",
    "___\n",
    "\n",
    "## Cluster local\n",
    "\n",
    "Para fins de desenvolvimento, utilizamos imagens Docker para criar um cluster spark local. Esse cluster deve estar rodadndo para que o notebook funcione como esperado. Na raiz do projeto:\n",
    "\n",
    "```shell\n",
    "docker-compose up\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sConf = SparkConf(\"spark://localhost:7077\")\n",
    "sc = SparkContext(conf=sConf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Tdoso os arquivos de entrada serão tratados em único Dataframe\n",
    "\n",
    "```shell\n",
    "INPUT_DIR_PATH: caminho para o diretório com os arquivs .fna (FASTA)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to process : 10\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR_PATH = Path(\"/home/thiago/Dados/sparkAAI-1/data/genomes/\")\n",
    "files_to_process = [str(f) for f in INPUT_DIR_PATH.iterdir()]\n",
    "print(\"Files to process :\", len(files_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file lines to process 86243\n"
     ]
    }
   ],
   "source": [
    "fasta_plain_df = sc.textFile(','.join(files_to_process))\\\n",
    "            .map(lambda x: Row(row=x))\\\n",
    "            .zipWithIndex()\\\n",
    "            .toDF([\"row\",\"idx\"])\n",
    "\n",
    "print(\"raw file lines to process\", fasta_plain_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecionando o dataframe lido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                 row|idx|\n",
      "+--------------------+---+\n",
      "|[>ALPH01000001.1 ...|  0|\n",
      "|[TCTCCCAGCACTTAGG...|  1|\n",
      "|[CAACCTCTTTAGAGTT...|  2|\n",
      "|[ATATTAGAAAGTACTT...|  3|\n",
      "|[AATTCCCGCACTTCTT...|  4|\n",
      "|[CAGGACTTGTATCAAG...|  5|\n",
      "|[CCTGCAGTAACACATG...|  6|\n",
      "|[TCTTATTTCTCTCCAA...|  7|\n",
      "|[ATTCTACTTCTTGAAT...|  8|\n",
      "|[CAACCTCCTGTTTTTA...|  9|\n",
      "|[CCACATTAAATCTATA...| 10|\n",
      "|[AATCTTGATTCAATTT...| 11|\n",
      "|[CCACCAAATCTCCTAT...| 12|\n",
      "|[ATCCGTTATATAAATT...| 13|\n",
      "|[GCAAGTCAGGATCTTG...| 14|\n",
      "|[CCTGAGATTGACTTCC...| 15|\n",
      "|[TGTAAATTGATCATTA...| 16|\n",
      "|[CGCCAATAAATTTGAT...| 17|\n",
      "|[AGAAATTTCACCTCTT...| 18|\n",
      "|[TTTAGAAACTTTAATT...| 19|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_plain_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse dos arquivos FASTA\n",
    "\n",
    "os arquivos [FASTA]([FASTA](https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp)), tem o seguinte formato:\n",
    "\n",
    "```\n",
    ">ID.CONTIG\n",
    "ATTC....\n",
    "GCG...\n",
    "CCG...\n",
    ">ID2.CONTIG\n",
    "GGC...\n",
    "...\n",
    "```\n",
    "\n",
    "nesta primeira sessão fazermos um parse desses arquivos para agrupar as sequẽncias por ID, calcular os kmers para esses contigs e obter um map com as freqências dos kmers em todos os contigs de uma sequẽncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta_id_line(l):\n",
    "    \"\"\"\n",
    "    Desejamos extrair os IDs das sequências da linhas que começarem pelo caracter ''>'. Pelo padrão\n",
    "    FASTA, o ID é a primeira palavra e é um campo composto por ID.CONTIG\n",
    "    \n",
    "    Input>\n",
    "        l: Uma linha de um arquivo FASTA\n",
    "    Return:\n",
    "        ID: da sequência ignorando o número de contigs, ou None caso não seja uma linha de ID\n",
    "    \"\"\"\n",
    "    if l[0][0] == \">\":\n",
    "        heaer_splits = l[0][1:].split(\" \")[0]\n",
    "        seq_id_split = heaer_splits.split(\".\")\n",
    "        return seq_id_split[0]\n",
    "    else:\n",
    "        return None\n",
    "seq2kmer_udf = udf(parse_fasta_id_line, T.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_null_ids_df = fasta_plain_df.withColumn(\"seqID_wNull\", seq2kmer_udf(\"row\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecionar o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------------+\n",
      "|                 row|idx| seqID_wNull|\n",
      "+--------------------+---+------------+\n",
      "|[>ALPH01000001.1 ...|  0|ALPH01000001|\n",
      "|[TCTCCCAGCACTTAGG...|  1|        null|\n",
      "|[CAACCTCTTTAGAGTT...|  2|        null|\n",
      "|[ATATTAGAAAGTACTT...|  3|        null|\n",
      "|[AATTCCCGCACTTCTT...|  4|        null|\n",
      "|[CAGGACTTGTATCAAG...|  5|        null|\n",
      "|[CCTGCAGTAACACATG...|  6|        null|\n",
      "|[TCTTATTTCTCTCCAA...|  7|        null|\n",
      "|[ATTCTACTTCTTGAAT...|  8|        null|\n",
      "|[CAACCTCCTGTTTTTA...|  9|        null|\n",
      "|[CCACATTAAATCTATA...| 10|        null|\n",
      "|[AATCTTGATTCAATTT...| 11|        null|\n",
      "|[CCACCAAATCTCCTAT...| 12|        null|\n",
      "|[ATCCGTTATATAAATT...| 13|        null|\n",
      "|[GCAAGTCAGGATCTTG...| 14|        null|\n",
      "|[CCTGAGATTGACTTCC...| 15|        null|\n",
      "|[TGTAAATTGATCATTA...| 16|        null|\n",
      "|[CGCCAATAAATTTGAT...| 17|        null|\n",
      "|[AGAAATTTCACCTCTT...| 18|        null|\n",
      "|[TTTAGAAACTTTAATT...| 19|        null|\n",
      "+--------------------+---+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_null_ids_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de seuências para serem processadas 84379\n"
     ]
    }
   ],
   "source": [
    "num_ids = fasta_null_ids_df.where(F.col(\"seqID_wNull\").isNull()).count()\n",
    "print(\"número de seuências para serem processadas\", num_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "desejamos fazer um \"fillna\" com o último valor não nulo encontrado na coluna de sequência, para isso usaremos um operador de janela deslizante em cima do índice que serve para manter a ordem original das linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_n_filter_df = fasta_null_ids_df.withColumn(\n",
    "    \"seqID\", F.last('seqID_wNull', ignorenulls=True)\\\n",
    "    .over(Window\\\n",
    "    .orderBy('idx')\\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir devemos excluir as linhas de header e renomear as colunas excluíndo as que não foram utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_df = fasta_n_filter_df\\\n",
    "                .where(F.col(\"seqID_wNull\").isNull())\\\n",
    "                .select(\"seqID\",\"row\")\\\n",
    "                .toDF(\"seqID\",\"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dataframe tratado tem o seguinte esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seqID: string (nullable = true)\n",
      " |-- seq: struct (nullable = true)\n",
      " |    |-- row: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspeção do daframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|       seqID|                 seq|\n",
      "+------------+--------------------+\n",
      "|ALPH01000001|[TCTCCCAGCACTTAGG...|\n",
      "|ALPH01000001|[CAACCTCTTTAGAGTT...|\n",
      "|ALPH01000001|[ATATTAGAAAGTACTT...|\n",
      "|ALPH01000001|[AATTCCCGCACTTCTT...|\n",
      "|ALPH01000001|[CAGGACTTGTATCAAG...|\n",
      "|ALPH01000001|[CCTGCAGTAACACATG...|\n",
      "|ALPH01000001|[TCTTATTTCTCTCCAA...|\n",
      "|ALPH01000001|[ATTCTACTTCTTGAAT...|\n",
      "|ALPH01000001|[CAACCTCCTGTTTTTA...|\n",
      "|ALPH01000001|[CCACATTAAATCTATA...|\n",
      "|ALPH01000001|[AATCTTGATTCAATTT...|\n",
      "|ALPH01000001|[CCACCAAATCTCCTAT...|\n",
      "|ALPH01000001|[ATCCGTTATATAAATT...|\n",
      "|ALPH01000001|[GCAAGTCAGGATCTTG...|\n",
      "|ALPH01000001|[CCTGAGATTGACTTCC...|\n",
      "|ALPH01000001|[TGTAAATTGATCATTA...|\n",
      "|ALPH01000001|[CGCCAATAAATTTGAT...|\n",
      "|ALPH01000001|[AGAAATTTCACCTCTT...|\n",
      "|ALPH01000001|[TTTAGAAACTTTAATT...|\n",
      "|ALPH01000001|[CCCATCTTCCATTACC...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Kmers\n",
    "\n",
    "Nesta sessão faremos o cálculo dos [kmers](https://en.wikipedia.org/wiki/K-mer) de tambo ```K```. O objetivo é associar cada ID de sequência ao conjunto de kmers distiontos presentes em todos os seus motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2kmerTy = T.ArrayType(T.StringType())\n",
    "def seq2kmer(seq_):\n",
    "    global K\n",
    "    value = seq_[0].strip()\n",
    "    num_kmers = len(value) - K + 1\n",
    "    kmers_list = [value[n*K:K*(n+1)] for n in range(0, num_kmers)]\n",
    "    \n",
    "    # return len(value)\n",
    "    return kmers_list\n",
    "\n",
    "seq2kmer_udf = udf(seq2kmer,Seq2kmerTy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_kmers_df = fasta_df\\\n",
    "        .withColumn(\"kmers\", seq2kmer_udf(\"seq\"))\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspeção do daframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seqID: string (nullable = true)\n",
      " |-- seq: struct (nullable = true)\n",
      " |    |-- row: string (nullable = true)\n",
      " |-- kmers: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_kmers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+\n",
      "|       seqID|                 seq|               kmers|\n",
      "+------------+--------------------+--------------------+\n",
      "|ALPH01000001|[TCTCCCAGCACTTAGG...|[TCT, CCC, AGC, A...|\n",
      "|ALPH01000001|[CAACCTCTTTAGAGTT...|[CAA, CCT, CTT, T...|\n",
      "|ALPH01000001|[ATATTAGAAAGTACTT...|[ATA, TTA, GAA, A...|\n",
      "|ALPH01000001|[AATTCCCGCACTTCTT...|[AAT, TCC, CGC, A...|\n",
      "|ALPH01000001|[CAGGACTTGTATCAAG...|[CAG, GAC, TTG, T...|\n",
      "|ALPH01000001|[CCTGCAGTAACACATG...|[CCT, GCA, GTA, A...|\n",
      "|ALPH01000001|[TCTTATTTCTCTCCAA...|[TCT, TAT, TTC, T...|\n",
      "|ALPH01000001|[ATTCTACTTCTTGAAT...|[ATT, CTA, CTT, C...|\n",
      "|ALPH01000001|[CAACCTCCTGTTTTTA...|[CAA, CCT, CCT, G...|\n",
      "|ALPH01000001|[CCACATTAAATCTATA...|[CCA, CAT, TAA, A...|\n",
      "|ALPH01000001|[AATCTTGATTCAATTT...|[AAT, CTT, GAT, T...|\n",
      "|ALPH01000001|[CCACCAAATCTCCTAT...|[CCA, CCA, AAT, C...|\n",
      "|ALPH01000001|[ATCCGTTATATAAATT...|[ATC, CGT, TAT, A...|\n",
      "|ALPH01000001|[GCAAGTCAGGATCTTG...|[GCA, AGT, CAG, G...|\n",
      "|ALPH01000001|[CCTGAGATTGACTTCC...|[CCT, GAG, ATT, G...|\n",
      "|ALPH01000001|[TGTAAATTGATCATTA...|[TGT, AAA, TTG, A...|\n",
      "|ALPH01000001|[CGCCAATAAATTTGAT...|[CGC, CAA, TAA, A...|\n",
      "|ALPH01000001|[AGAAATTTCACCTCTT...|[AGA, AAT, TTC, A...|\n",
      "|ALPH01000001|[TTTAGAAACTTTAATT...|[TTT, AGA, AAC, T...|\n",
      "|ALPH01000001|[CCCATCTTCCATTACC...|[CCC, ATC, TTC, C...|\n",
      "+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_kmers_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validação, podemos obter estatísticas básicas dso kmers obtidos. Para isso vamos contar o número de kmers por ID de sequência e obter um describe da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kmers_df = fasta_kmers_df\\\n",
    "                    .withColumn(\"n_kmers\", size(col(\"kmers\")))\\\n",
    "                    .select(\"n_kmers\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|          n_kmers|\n",
      "+-------+-----------------+\n",
      "|  count|            84379|\n",
      "|   mean|77.11937804430012|\n",
      "| stddev|6.794605271811715|\n",
      "|    min|                0|\n",
      "|    max|               78|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_kmers_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das Sequências \n",
    "\n",
    "A seguir analisaremos as sequẽncias a partir dos kmers obtidos. O profile de uma seuquência é um mapeamento ```kmer->num ocorrencias``` que pode ser utilizado em análises de similaridade entre sequências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "KmerFreqTuple = T.MapType(T.StringType(), T.IntegerType())\n",
    "\n",
    "def kmers_list2kmers_freq_dict(kmers_list):\n",
    "    \"\"\"\n",
    "    Cálcula as frequências absolutas de cda kmer no dataframe\n",
    "    Retorna:\n",
    "        Um onjeto map(\"kmer\" -> número de ocorrências ) para cada sequência\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(kmers_list[0], return_counts=True)\n",
    "    kmers_map = {str(k):int(v) for k, v in zip(unique, counts) if k}\n",
    "    return kmers_map\n",
    "\n",
    "kmers_list2kmers_freq_dict_udf = udf(kmers_list2kmers_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmers_pofile_df = fasta_kmers_df\\\n",
    "            .groupby(\"seqID\")\\\n",
    "            .agg(F.collect_list('kmers').alias('kmers_list'))\\\n",
    "            .withColumn('kmers_freq', kmers_list2kmers_freq_dict_udf('kmers_list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seqID: string (nullable = true)\n",
      " |-- kmers_list: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- kmers_freq: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmers_pofile_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|       seqID|          kmers_freq|\n",
      "+------------+--------------------+\n",
      "|ALPC01000098|{TGT=1, AA=1, AAA...|\n",
      "|ALPG01000168|{TTA=1, TT=1, TGT...|\n",
      "|ALPH01000049|{TTA=1, TT=1, ATT...|\n",
      "|ALPH01000154|{ATT=3, AAA=1, TT...|\n",
      "|ALPI01000077|{TTA=1, CCA=1, AA...|\n",
      "|ALPJ01000168|{TGT=1, GGA=1, AG...|\n",
      "|ALPK01000207|{TT=1, ATT=2, CGG...|\n",
      "|ALPD01000057|{TTA=2, GGA=1, AT...|\n",
      "|ALPH01000006|{GGA=1, CCA=2, CC...|\n",
      "|ALPH01000151|{TTA=1, ATT=1, TC...|\n",
      "|ALPH01000275|{TGT=1, ATT=1, AC...|\n",
      "|ALPI01000038|{TTA=1, TGT=1, GG...|\n",
      "|ALPJ01000066|{TTA=1, AGG=2, AA...|\n",
      "|ALPJ01000133|{TTA=2, TT=1, ATT...|\n",
      "|ALPJ01000183|{CCA=1, ATT=1, AC...|\n",
      "|ALPK01000019|{TTA=1, TT=1, GGA...|\n",
      "|ALPK01000076|{TTA=2, ATT=2, AA...|\n",
      "|ALPK01000121|{TTA=1, TGT=1, GG...|\n",
      "|ALPC01000044|{CCA=2, ATT=1, AA...|\n",
      "|ALPC01000071|{TTA=2, AGG=1, CC...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmers_pofile_df.select(\"seqID\", \"kmers_freq\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterização\n",
    "\n",
    "O número de K que defie o tamanho dos k-mers define um espaço de features de dimensão $4^K$, para codificar essas features podemos usar a classe ```CountVectorizer```. Essa codificação atribui ordinais a cada kmer único e cria duas listas para representar a presença e o frequência absoluta dos mesmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmers_df = fasta_kmers_df.select(\"seqID\", \"kmers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"kmers\", outputCol=\"features\")\n",
    "\n",
    "model = cv.fit(kmers_df)\n",
    "\n",
    "features_df = model.transform(kmers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+\n",
      "|       seqID|               kmers|            features|\n",
      "+------------+--------------------+--------------------+\n",
      "|ALPH01000001|[TCT, CCC, AGC, A...|(93,[0,2,3,8,10,1...|\n",
      "|ALPH01000001|[CAA, CCT, CTT, T...|(93,[0,2,4,5,9,10...|\n",
      "|ALPH01000001|[ATA, TTA, GAA, A...|(93,[0,3,4,6,7,9,...|\n",
      "|ALPH01000001|[AAT, TCC, CGC, A...|(93,[0,2,3,4,5,7,...|\n",
      "|ALPH01000001|[CAG, GAC, TTG, T...|(93,[0,4,6,8,9,10...|\n",
      "|ALPH01000001|[CCT, GCA, GTA, A...|(93,[0,1,4,6,7,12...|\n",
      "|ALPH01000001|[TCT, TAT, TTC, T...|(93,[0,1,2,4,8,11...|\n",
      "|ALPH01000001|[ATT, CTA, CTT, C...|(93,[0,1,2,3,4,6,...|\n",
      "|ALPH01000001|[CAA, CCT, CCT, G...|(93,[0,2,3,4,6,9,...|\n",
      "|ALPH01000001|[CCA, CAT, TAA, A...|(93,[0,2,3,4,5,7,...|\n",
      "|ALPH01000001|[AAT, CTT, GAT, T...|(93,[0,2,3,4,5,6,...|\n",
      "|ALPH01000001|[CCA, CCA, AAT, C...|(93,[0,1,2,3,6,7,...|\n",
      "|ALPH01000001|[ATC, CGT, TAT, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000001|[GCA, AGT, CAG, G...|(93,[0,2,3,4,5,6,...|\n",
      "|ALPH01000001|[CCT, GAG, ATT, G...|(93,[0,2,3,4,5,12...|\n",
      "|ALPH01000001|[TGT, AAA, TTG, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000001|[CGC, CAA, TAA, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000001|[AGA, AAT, TTC, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000001|[TTT, AGA, AAC, T...|(93,[0,2,3,4,5,8,...|\n",
      "|ALPH01000001|[CCC, ATC, TTC, C...|(93,[0,2,3,6,7,8,...|\n",
      "+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Para o ajuste dos hiperparâmetros da clusterização devemos fazer um parameter sweep para achar o número ideal de clusters. A avaliação da qualidade do cluster é dada pela [Métreica de Silhouette](https://spark.apache.org/docs/2.3.1/api/java/org/apache/spark/ml/evaluation/ClusteringEvaluator.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkm = BisectingKMeans()\n",
    "# model = bkm.fit(features_df)\n",
    "clustering_pipeline = Pipeline(stages=[bkm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(bkm.k, [2, 5, 10, 20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=clustering_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=ClusteringEvaluator(),\n",
    "                          numFolds=5)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel, folds = crossval.fit(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = cvModel.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.select(\"prediction\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_env",
   "language": "python",
   "name": "bio_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
